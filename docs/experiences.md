# Contexte professionnel et technique

Cette page apporte un **complément de contexte** au portfolio.  
Elle synthétise mon parcours et mes compétences sous l’angle de la **conception de plateformes data**, de la **construction de pipelines fiables** et de la **production de données analytiques exploitables**, dans une logique **Data Engineer / Analytics Engineer**.

---

## Expériences clés

### Inria — Data Engineer (Data Platform)
- Conception et évolution d’une data platform cloud orientée production.
- Développement de pipelines Python / SQL avec tests, documentation et contrôles de cohérence.
- Structuration de datasets analytiques utilisés par des équipes internes.
- Collaboration avec des profils data et techniques pour garantir stabilité et exploitabilité.

### Apteeus — Data Engineer
- Développement de pipelines ETL pour données structurées (TXT, CSV, Excel).
- Transformation, mise en qualité et documentation de données analytiques.
- Construction de bases cohérentes et maintenables dans le temps.

### Alicante — Analytics Engineer
- Ingestion et normalisation de sources tabulaires hétérogènes.
- Conception de transformations analytiques automatisées.
- Production de datasets exploitables par des utilisateurs métier.

---

## Projets significatifs

### Data Platform — Cas d’usage agence média
- Plateforme data simulant un contexte d’agence média.
- Centralisation de sources hétérogènes et automatisation ingestion / transformation.
- Production de datasets analytiques structurés et prêts à l’usage.

### CHU de Lille — Projet Data (Master 2 Data Science)
- Préparation et analyse de données issues de signaux physiologiques.
- Mise en œuvre de méthodes de classification pour l’anticipation de crises d’épilepsie.
- Attention portée à la qualité, la cohérence et la reproductibilité.
- Collaboration avec des profils techniques et non techniques.

---

## Compétences techniques

**Data Engineering**
- Ingestion multi-sources et pipelines de données
- Orchestration et automatisation des traitements
- Fiabilité, gestion des erreurs et performance
- Data platforms et bases de données analytiques

**Analytics Engineering**
- Transformations analytiques SQL-first
- Modélisation et structuration des données
- Tables analytiques, tests et contrôles de qualité
- Documentation et exploitation des datasets

**Outils et environnements**
- Langages : Python, SQL  
- Orchestration : Airflow  
- Transformation analytique : dbt  
- Cloud & data platforms : GCP (BigQuery), Snowflake  
- Bases de données : PostgreSQL, MongoDB  
- Qualité & tests : dbt tests, tests SQL, pytest  
- Conteneurisation & CI/CD : Docker, GitHub Actions, GitLab CI  
- Collaboration : Git, GitHub, GitLab  
- Environnement : Linux, Bash

---

## Transmission et engagements

- Tutorat universitaire en programmation Python.
- Vulgarisation de concepts data et accompagnement de bonnes pratiques.
- Engagement associatif autour du logiciel libre et de projets collaboratifs.

---

## Synthèse

- Conception et exploitation de plateformes et pipelines data.
- Structuration et transformation de données à des fins analytiques.
- Forte attention à la qualité, la fiabilité et la documentation.
- Pratique régulière de la collaboration et de la transmission technique.
