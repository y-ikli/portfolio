{"config":{"lang":["fr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Accueil","text":"Portfolio \u2014 Data Engineer / Analytics Engineer Younes IKLI"},{"location":"#profil","title":"Profil","text":"<p>Data Engineer / Analytics Engineer sp\u00e9cialis\u00e9 dans la conception et l\u2019exploitation de plateformes data et de pipelines analytiques en production. Mon travail consiste \u00e0 construire des syst\u00e8mes fiables, lisibles et \u00e9volutifs, en tenant compte des contraintes op\u00e9rationnelles et de la qualit\u00e9 des donn\u00e9es.</p>"},{"location":"#ce-que-je-fais","title":"Ce que je fais","text":"<ul> <li>Concevoir et op\u00e9rer des pipelines d\u2019ingestion de donn\u00e9es. </li> <li>Structurer et transformer les donn\u00e9es pour des usages analytiques.  </li> <li>Orchestrer et automatiser les traitements.  </li> <li>Produire des tables analytiques fiables et exploitables.  </li> <li>Documenter et maintenir des syst\u00e8mes data dans la dur\u00e9e.</li> </ul>"},{"location":"#projet-principal","title":"Projet principal","text":"<p>Un projet end-to-end illustrant une plateforme data op\u00e9rationnelle :</p> <ul> <li>ingestion et normalisation de sources h\u00e9t\u00e9rog\u00e8nes  </li> <li>orchestration des traitements  </li> <li>transformations analytiques contr\u00f4l\u00e9es  </li> <li>tables analytiques pr\u00eates \u00e0 \u00eatre consomm\u00e9es</li> </ul> <p>\u27a1\ufe0f Voir le projet</p>"},{"location":"competences/","title":"Comp\u00e9tences","text":"Comp\u00e9tences <p>Mon profil couvre \u00e0 la fois les dimensions Data Engineering et Analytics Engineering. Cette double comp\u00e9tence me permet d\u2019intervenir sur l\u2019ensemble du cycle de vie de la donn\u00e9e, depuis l\u2019ingestion jusqu\u2019\u00e0 la mise \u00e0 disposition de jeux de donn\u00e9es exploitables.</p>"},{"location":"competences/#competences-techniques","title":"Comp\u00e9tences techniques","text":""},{"location":"competences/#data-engineering","title":"Data Engineering","text":"<ul> <li>Pipelines de donn\u00e9es  </li> <li>Ingestion multi-sources  </li> <li>Orchestration des traitements  </li> <li>Bases de donn\u00e9es analytiques  </li> <li>Gestion des erreurs et reprises  </li> <li>Performance et fiabilit\u00e9</li> </ul>"},{"location":"competences/#analytics-engineering","title":"Analytics Engineering","text":"<ul> <li>Transformations analytiques  </li> <li>Mod\u00e9lisation des donn\u00e9es  </li> <li>Tables analytiques  </li> <li>Tests et contr\u00f4les de donn\u00e9es  </li> <li>Documentation des mod\u00e8les  </li> <li>Exploitation des donn\u00e9es</li> </ul>"},{"location":"competences/#soft-skills","title":"Soft skills","text":"<ul> <li> <p>Sens des responsabilit\u00e9s   Habitude de travailler dans des environnements o\u00f9 la fiabilit\u00e9, la confidentialit\u00e9 et la qualit\u00e9 sont essentielles.</p> </li> <li> <p>Approche p\u00e9dagogique   Capacit\u00e9 \u00e0 transmettre, documenter et accompagner, acquise notamment par des exp\u00e9riences d\u2019enseignement et de mentorat.</p> </li> <li> <p>Autonomie et engagement   Implication forte dans les projets, avec une attention particuli\u00e8re port\u00e9e \u00e0 leur maintenabilit\u00e9 et \u00e0 leur \u00e9volution dans le temps.</p> </li> </ul>"},{"location":"competences/#outils-et-environnements","title":"Outils et environnements","text":"<ul> <li>Syst\u00e8mes et environnement : Linux, ligne de commande, Bash  </li> <li>Langages : Python, SQL  </li> <li>Orchestration et automatisation : Airflow  </li> <li>Transformation analytique : dbt  </li> <li>Cloud et data platforms : GCP (BigQuery), Snowflake  </li> <li>Bases de donn\u00e9es : PostgreSQL, MongoDB  </li> <li>Qualit\u00e9 et tests : tests SQL, dbt tests, pytest  </li> <li>Conteneurisation : Docker  </li> <li>Int\u00e9gration continue : GitHub Actions, GitLab CI  </li> <li>Contr\u00f4le de version et collaboration : Git, GitHub, GitLab</li> </ul>"},{"location":"experiences/","title":"Exp\u00e9riences","text":"Exp\u00e9riences <p>Cette page pr\u00e9sente mes exp\u00e9riences sous l\u2019angle des responsabilit\u00e9s data, de la construction de pipelines et de la mise \u00e0 disposition de donn\u00e9es exploitables, dans une logique orient\u00e9e Data Engineer / Analytics Engineer.</p>"},{"location":"experiences/#experiences-data","title":"Exp\u00e9riences Data","text":""},{"location":"experiences/#inria","title":"Inria","text":"<p>Data Engineer \u2014 Data Platform </p> <ul> <li>Mise en place et \u00e9volution d\u2019une data platform cloud d\u00e9di\u00e9e au d\u00e9veloppement et \u00e0 la fiabilisation de pipelines de donn\u00e9es.</li> <li>D\u00e9veloppement de pipelines en Python et SQL, avec tests, documentation et contr\u00f4les de coh\u00e9rence.</li> <li>Structuration des flux et des jeux de donn\u00e9es analytiques utilis\u00e9s par des \u00e9quipes internes.</li> <li>Collaboration avec diff\u00e9rents profils techniques pour garantir l\u2019exploitabilit\u00e9 et la stabilit\u00e9 des donn\u00e9es.</li> </ul>"},{"location":"experiences/#apteeus","title":"Apteeus","text":"<p>Data Engineer </p> <ul> <li>D\u00e9veloppement de pipelines ETL en Python pour l\u2019ingestion de donn\u00e9es issues de fichiers structur\u00e9s (TXT, CSV, Excel).</li> <li>Transformation, mise en qualit\u00e9 et documentation de donn\u00e9es \u00e0 destination d\u2019usages analytiques et de reporting.</li> <li>Construction de bases analytiques coh\u00e9rentes et exploitables dans le temps.</li> </ul>"},{"location":"experiences/#alicante","title":"Alicante","text":"<p>Analytics Engineer </p> <ul> <li>Ingestion de sources tabulaires h\u00e9t\u00e9rog\u00e8nes et normalisation des donn\u00e9es.</li> <li>Conception de transformations analytiques et de pipelines param\u00e9trables.</li> <li>Production de jeux de donn\u00e9es exploitables par des utilisateurs m\u00e9tier.</li> </ul>"},{"location":"experiences/#projets-data-appliques","title":"Projets Data appliqu\u00e9s","text":""},{"location":"experiences/#chu-de-lille","title":"CHU de Lille","text":"<p>Projet Data \u2014 Master 2 Data Science </p> <ul> <li>Projet professionnel r\u00e9alis\u00e9 dans le cadre du Master 2.</li> <li>Pr\u00e9paration, structuration et analyse de jeux de donn\u00e9es complexes issus d\u2019un contexte r\u00e9el.</li> <li>Travaux de classification, s\u00e9lection de variables et gestion de donn\u00e9es d\u00e9s\u00e9quilibr\u00e9es.</li> <li>Mise en place de contr\u00f4les de coh\u00e9rence et attention port\u00e9e \u00e0 la qualit\u00e9 et \u00e0 la reproductibilit\u00e9 des traitements.</li> <li>Collaboration avec des profils techniques et non techniques autour des usages des donn\u00e9es.</li> </ul>"},{"location":"experiences/#ce-projet-illustre-une-experience-data-appliquee-dans-un-contexte-metier","title":"&gt; Ce projet illustre une exp\u00e9rience data appliqu\u00e9e dans un contexte m\u00e9tier.","text":""},{"location":"experiences/#transmission-et-accompagnement-technique","title":"Transmission et accompagnement technique","text":"<ul> <li>Tutorat universitaire en programmation Python.</li> <li>Vulgarisation de concepts techniques aupr\u00e8s de publics non sp\u00e9cialis\u00e9s.</li> <li>Accompagnement et transmission de bonnes pratiques autour du code et des donn\u00e9es.</li> </ul>"},{"location":"experiences/#engagements-et-activites-annexes","title":"Engagements et activit\u00e9s annexes","text":"<p>Conseil de d\u00e9veloppement \u2014 M\u00e9tropole Europ\u00e9enne de Lille  - Participation \u00e0 des groupes de travail et ateliers th\u00e9matiques. - Travail collaboratif avec des acteurs institutionnels et associatifs.</p> <p>Association Alis Conseiller \u2014 Promotion du logiciel libre </p> <ul> <li>Contribution \u00e0 des initiatives de diffusion du logiciel libre.</li> <li>Organisation et animation d\u2019ateliers techniques.</li> <li>Coordination de projets et d\u2019\u00e9quipes b\u00e9n\u00e9voles.</li> </ul>"},{"location":"experiences/#synthese","title":"Synth\u00e8se","text":"<p>Ces exp\u00e9riences mettent en \u00e9vidence :</p> <ul> <li>la conception et l\u2019exploitation de plateformes et de pipelines data,</li> <li>la structuration et la transformation de donn\u00e9es \u00e0 des fins analytiques,</li> <li>la capacit\u00e9 \u00e0 documenter, fiabiliser et rendre exploitables des jeux de donn\u00e9es,</li> <li>une pratique r\u00e9guli\u00e8re de la collaboration et de la transmission technique.</li> </ul>"},{"location":"projets/","title":"Liste des projets","text":"Projets <p>D\u00e9couvrez mes principaux projets ci-dessous.</p>"},{"location":"projets/#plateforme-data-marketing","title":"Plateforme Data Marketing","text":"<p>Une plateforme data marketing moderne, modulaire et cloud-ready pour unifier, fiabiliser et valoriser les donn\u00e9es issues de multiples r\u00e9gies publicitaires.</p>"},{"location":"projets/#probleme","title":"Probl\u00e8me","text":"<p>Les donn\u00e9es marketing proviennent de multiples plateformes (Google Ads, Meta Ads, TikTok, LinkedIn, etc.) avec : - Sch\u00e9mas h\u00e9t\u00e9rog\u00e8nes et d\u00e9finitions KPI non harmonis\u00e9es - Ingestions peu industrialis\u00e9es et fragiles - Couplage fort entre reporting et syst\u00e8mes sources - Absence de qualit\u00e9 de donn\u00e9es garantie</p>"},{"location":"projets/#solution","title":"Solution","text":"<ul> <li>Architecture cloud-ready, modulaire et extensible</li> <li>Ajout de nouveaux connecteurs via interface standardis\u00e9e</li> <li>Pipelines d'ingestion incr\u00e9mentaux, idempotents et test\u00e9s (Airflow, dbt, CI/CD)</li> <li>S\u00e9paration stricte des couches (Raw \u2192 Staging \u2192 Intermediate \u2192 Marts)</li> <li>Monitoring, tests automatis\u00e9s, documentation et tra\u00e7abilit\u00e9</li> </ul>"},{"location":"projets/#impact","title":"Impact","text":"<ul> <li>Int\u00e9gration de nouvelles sources en moins d\u2019un jour (vs. semaines)</li> <li>0 anomalies en production gr\u00e2ce aux tests automatis\u00e9s</li> <li>Centralisation et fiabilit\u00e9 des donn\u00e9es pour acc\u00e9l\u00e9rer la prise de d\u00e9cision et l\u2019innovation data</li> </ul>"},{"location":"projets/#fonctionnalites-principales","title":"Fonctionnalit\u00e9s principales","text":"<ul> <li>Ingestion incr\u00e9mentale et idempotente de donn\u00e9es multi-sources</li> <li>Orchestration centralis\u00e9e (Airflow)</li> <li>Transformations SQL-first (dbt)</li> <li>Monitoring, tests et CI/CD int\u00e9gr\u00e9s</li> <li>Pr\u00eat pour le cloud (BigQuery, Snowflake)</li> </ul>"},{"location":"projets/#a-voir-sur-github","title":"\u00c0 voir sur GitHub","text":"<ul> <li>Code source, documentation technique, guides d\u2019utilisation, scripts de d\u00e9mo et architecture d\u00e9taill\u00e9e</li> </ul> <p>Voir le d\u00e9p\u00f4t GitHub</p>"}]}