{"config":{"lang":["fr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Portfolio \u2014 Younes IKLI","text":""},{"location":"#presentation","title":"Pr\u00e9sentation","text":"<p>Ing\u00e9nieur Data orient\u00e9 produit, j\u2019interviens au croisement du Data Engineering et de l\u2019Analytics Engineering. Je con\u00e7ois des plateformes data robustes et des couches analytiques fiables, permettant de transformer des donn\u00e9es complexes en indicateurs clairs et actionnables pour les \u00e9quipes produit et m\u00e9tier.</p>"},{"location":"#tldr-analytics-engineering-view","title":"TL;DR \u2013 Analytics Engineering View","text":"<p>Construction et fiabilisation de la couche analytique au service du produit et du business.</p> <ul> <li>Mod\u00e9lisation analytique SQL-first avec dbt (facts / dimensions, grain ma\u00eetris\u00e9)</li> <li>Harmonisation et gouvernance des KPIs m\u00e9tier</li> <li>Tests automatis\u00e9s, documentation et qualit\u00e9 des donn\u00e9es en production</li> <li>Livraison de data marts BI-ready pour \u00e9quipes produit, business et clients</li> </ul>"},{"location":"#tldr-data-engineering-view","title":"TL;DR \u2013 Data Engineering View","text":"<p>Conception et exploitation de data platforms fiables et scalables en environnement cloud.</p> <ul> <li>Ingestion multi-sources et pipelines incr\u00e9mentaux orchestr\u00e9s (Airflow)</li> <li>Architectures modulaires, cloud-ready et orient\u00e9es production</li> <li>Monitoring, CI/CD et observabilit\u00e9 des pipelines</li> <li>Scalabilit\u00e9, r\u00e9silience et maintenabilit\u00e9 des syst\u00e8mes data</li> </ul>"},{"location":"#projet-principal","title":"Projet principal","text":"<p>Un projet end-to-end illustrant un socle data unique, lisible selon deux angles compl\u00e9mentaires :</p> <ul> <li>Analytics Engineering : mod\u00e9lisation analytique, KPIs, qualit\u00e9 et usages m\u00e9tier</li> <li>Data Engineering : ingestion, orchestration, architecture et robustesse production</li> </ul> <p>Fonctionnalit\u00e9s cl\u00e9s : - Ingestion et normalisation de sources h\u00e9t\u00e9rog\u00e8nes - Orchestration des traitements data - Transformations analytiques contr\u00f4l\u00e9es - Tables analytiques pr\u00eates \u00e0 \u00eatre consomm\u00e9es par la BI et les \u00e9quipes produit</p> <p>\u27a1\ufe0f Voir le projet</p>  Contexte professionnel et technique : consulter"},{"location":"experiences/","title":"Contexte professionnel et technique","text":"<p>Cette page apporte un compl\u00e9ment de contexte au portfolio. Elle synth\u00e9tise mon parcours et mes comp\u00e9tences sous l\u2019angle de la conception de plateformes data, de la construction de pipelines fiables et de la production de donn\u00e9es analytiques exploitables, dans une logique Data Engineer / Analytics Engineer.</p>"},{"location":"experiences/#experiences-cles","title":"Exp\u00e9riences cl\u00e9s","text":""},{"location":"experiences/#inria-data-engineer-data-platform","title":"Inria \u2014 Data Engineer (Data Platform)","text":"<ul> <li>Conception et \u00e9volution d\u2019une data platform cloud orient\u00e9e production.</li> <li>D\u00e9veloppement de pipelines Python / SQL avec tests, documentation et contr\u00f4les de coh\u00e9rence.</li> <li>Structuration de datasets analytiques utilis\u00e9s par des \u00e9quipes internes.</li> <li>Collaboration avec des profils data et techniques pour garantir stabilit\u00e9 et exploitabilit\u00e9.</li> </ul>"},{"location":"experiences/#apteeus-data-engineer","title":"Apteeus \u2014 Data Engineer","text":"<ul> <li>D\u00e9veloppement de pipelines ETL pour donn\u00e9es structur\u00e9es (TXT, CSV, Excel).</li> <li>Transformation, mise en qualit\u00e9 et documentation de donn\u00e9es analytiques.</li> <li>Construction de bases coh\u00e9rentes et maintenables dans le temps.</li> </ul>"},{"location":"experiences/#alicante-analytics-engineer","title":"Alicante \u2014 Analytics Engineer","text":"<ul> <li>Ingestion et normalisation de sources tabulaires h\u00e9t\u00e9rog\u00e8nes.</li> <li>Conception de transformations analytiques automatis\u00e9es.</li> <li>Production de datasets exploitables par des utilisateurs m\u00e9tier.</li> </ul>"},{"location":"experiences/#projets-significatifs","title":"Projets significatifs","text":""},{"location":"experiences/#data-platform-cas-dusage-agence-media","title":"Data Platform \u2014 Cas d\u2019usage agence m\u00e9dia","text":"<ul> <li>Plateforme data simulant un contexte d\u2019agence m\u00e9dia.</li> <li>Centralisation de sources h\u00e9t\u00e9rog\u00e8nes et automatisation ingestion / transformation.</li> <li>Production de datasets analytiques structur\u00e9s et pr\u00eats \u00e0 l\u2019usage.</li> </ul>"},{"location":"experiences/#chu-de-lille-projet-data-master-2-data-science","title":"CHU de Lille \u2014 Projet Data (Master 2 Data Science)","text":"<ul> <li>Pr\u00e9paration et analyse de donn\u00e9es issues de signaux physiologiques.</li> <li>Mise en \u0153uvre de m\u00e9thodes de classification pour l\u2019anticipation de crises d\u2019\u00e9pilepsie.</li> <li>Attention port\u00e9e \u00e0 la qualit\u00e9, la coh\u00e9rence et la reproductibilit\u00e9.</li> <li>Collaboration avec des profils techniques et non techniques.</li> </ul>"},{"location":"experiences/#competences-techniques","title":"Comp\u00e9tences techniques","text":"<p>Data Engineering - Ingestion multi-sources et pipelines de donn\u00e9es - Orchestration et automatisation des traitements - Fiabilit\u00e9, gestion des erreurs et performance - Data platforms et bases de donn\u00e9es analytiques</p> <p>Analytics Engineering - Transformations analytiques SQL-first - Mod\u00e9lisation et structuration des donn\u00e9es - Tables analytiques, tests et contr\u00f4les de qualit\u00e9 - Documentation et exploitation des datasets</p> <p>Outils et environnements - Langages : Python, SQL - Orchestration : Airflow - Transformation analytique : dbt - Cloud &amp; data platforms : GCP (BigQuery), Snowflake - Bases de donn\u00e9es : PostgreSQL, MongoDB - Qualit\u00e9 &amp; tests : dbt tests, tests SQL, pytest - Conteneurisation &amp; CI/CD : Docker, GitHub Actions, GitLab CI - Collaboration : Git, GitHub, GitLab - Environnement : Linux, Bash</p>"},{"location":"experiences/#transmission-et-engagements","title":"Transmission et engagements","text":"<ul> <li>Tutorat universitaire en programmation Python.</li> <li>Vulgarisation de concepts data et accompagnement de bonnes pratiques.</li> <li>Engagement associatif autour du logiciel libre et de projets collaboratifs.</li> </ul>"},{"location":"experiences/#synthese","title":"Synth\u00e8se","text":"<ul> <li>Conception et exploitation de plateformes et pipelines data.</li> <li>Structuration et transformation de donn\u00e9es \u00e0 des fins analytiques.</li> <li>Forte attention \u00e0 la qualit\u00e9, la fiabilit\u00e9 et la documentation.</li> <li>Pratique r\u00e9guli\u00e8re de la collaboration et de la transmission technique.</li> </ul>"},{"location":"projets/","title":"Liste des projets","text":"Projets <p>D\u00e9couvrez mes principaux projets ci-dessous.</p>"},{"location":"projets/#plateforme-data-marketing","title":"Plateforme Data Marketing","text":"<p>Une plateforme data marketing moderne, modulaire et cloud-ready pour unifier, fiabiliser et valoriser les donn\u00e9es issues de multiples r\u00e9gies publicitaires.</p>"},{"location":"projets/#probleme","title":"Probl\u00e8me","text":"<p>Les donn\u00e9es marketing proviennent de multiples plateformes (Google Ads, Meta Ads, TikTok, LinkedIn, etc.) avec : - Sch\u00e9mas h\u00e9t\u00e9rog\u00e8nes et d\u00e9finitions KPI non harmonis\u00e9es - Ingestions peu industrialis\u00e9es et fragiles - Couplage fort entre reporting et syst\u00e8mes sources - Absence de qualit\u00e9 de donn\u00e9es garantie</p>"},{"location":"projets/#solution","title":"Solution","text":"<ul> <li>Architecture cloud-ready, modulaire et extensible</li> <li>Ajout de nouveaux connecteurs via interface standardis\u00e9e</li> <li>Pipelines d'ingestion incr\u00e9mentaux, idempotents et test\u00e9s (Airflow, dbt, CI/CD)</li> <li>S\u00e9paration stricte des couches (Raw \u2192 Staging \u2192 Intermediate \u2192 Marts)</li> <li>Monitoring, tests automatis\u00e9s, documentation et tra\u00e7abilit\u00e9</li> </ul>"},{"location":"projets/#impact","title":"Impact","text":"<ul> <li>Int\u00e9gration de nouvelles sources en moins d\u2019un jour (vs. semaines)</li> <li>0 anomalies en production gr\u00e2ce aux tests automatis\u00e9s</li> <li>Centralisation et fiabilit\u00e9 des donn\u00e9es pour acc\u00e9l\u00e9rer la prise de d\u00e9cision et l\u2019innovation data</li> </ul>"},{"location":"projets/#fonctionnalites-principales","title":"Fonctionnalit\u00e9s principales","text":"<ul> <li>Ingestion incr\u00e9mentale et idempotente de donn\u00e9es multi-sources</li> <li>Orchestration centralis\u00e9e (Airflow)</li> <li>Transformations SQL-first (dbt)</li> <li>Monitoring, tests et CI/CD int\u00e9gr\u00e9s</li> <li>Pr\u00eat pour le cloud (BigQuery, Snowflake)</li> </ul>"},{"location":"projets/#apercu-de-la-plateforme-de-lorchestration-a-lanalyse","title":"Aper\u00e7u de la plateforme \u2014 de l\u2019orchestration \u00e0 l\u2019analyse","text":""},{"location":"projets/#orchestration-centralisee","title":"Orchestration centralis\u00e9e","text":"<p> Vue des DAGs Airflow orchestrant l\u2019ingestion multi-sources et les transformations analytiques.</p>"},{"location":"projets/#ingestion-des-donnees-brutes-raw-layer","title":"Ingestion des donn\u00e9es brutes (Raw layer)","text":"<p> Donn\u00e9es brutes issues de Google Ads et Meta Ads</p>"},{"location":"projets/#transformations-de-donnees-sql-first","title":"Transformations de donn\u00e9es (SQL-first)","text":"<p> Transformations SQL-first avec dbt, structur\u00e9es en couches staging, intermediate et marts.</p>"},{"location":"projets/#exposition-des-donnees-analytiques","title":"Exposition des donn\u00e9es analytiques","text":"<p> Jeux de donn\u00e9es analytiques orient\u00e9s m\u00e9tier, con\u00e7us pour la consommation BI, le reporting et les analyses marketing.</p>"},{"location":"projets/#voir-le-projet","title":"Voir le projet","text":"<p>L\u2019ensemble du code source, de la documentation technique et des choix d\u2019architecture est disponible sur GitHub : Consulter le d\u00e9p\u00f4t GitHub</p>"}]}